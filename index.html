<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8" />
  <title>Wortvorhersage mit LSTM</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.19.0/dist/tf.min.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,500,700&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <style>
/*     button {
      margin: 2px;
      padding: 6px 12px;
      font-size: 14px;
      cursor: pointer;
    }
    #output button {
      background-color: #f0f0f0;
      border: 1px solid #ccc;
      border-radius: 4px;
    }
    #output button:hover {
      background-color: #d0eaff;
    }
    h1, h2 {
      color: #1976d2;
    } */
    /* Material Design CSS für Wortvorhersage mit LSTM */
body {
  font-family: 'Roboto', 'Arial', sans-serif;
  background: #f5f7fa;
  color: #212121;
  margin: 0;
  padding: 0;
}

h1, h2, h3 {
  color: #1976d2;
  font-weight: 500;
  margin-bottom: 12px;
  letter-spacing: 0.5px;
}

h1 {
  font-size: 2.5rem;
  margin-top: 32px;
}

h2 {
  font-size: 1.5rem;
  margin-top: 28px;
}

#outer-container {
  background: #fff;
  margin: 32px auto 32px auto;
  max-width: 850px;
  box-shadow: 0 4px 20px rgba(0,0,0,0.09), 0 1.5px 5px rgba(0,0,0,0.04);
  border-radius: 16px;
  padding: 32px 40px 40px 40px;
}

textarea {
  width: 98%;
  max-width: 700px;
  font-size: 1.1rem;
  padding: 14px;
  border-radius: 8px;
  border: 1.5px solid #bdbdbd;
  background: #fafdff;
  box-shadow: 0 2px 8px rgba(25,118,210,0.02);
  margin-bottom: 12px;
  resize: vertical;
  transition: border-color 0.2s;
}

textarea:focus {
  outline: none;
  border-color: #1976d2;
  background: #fff;
}

button {
  background: #1976d2;
  color: #fff;
  border: none;
  border-radius: 28px;
  padding: 10px 26px;
  font-size: 1rem;
  font-weight: 500;
  box-shadow: 0 1px 5px rgba(25,118,210,0.09);
  margin: 3px 6px 3px 0;
  cursor: pointer;
  transition: background 0.2s, box-shadow 0.18s;
  letter-spacing: 0.1px;
  min-width: 110px;
}

button:hover, button:focus {
  background: #1565c0;
  box-shadow: 0 4px 18px rgba(25,118,210,0.13);
}

#output {
  margin-top: 28px;
  padding: 18px 20px;
  background: #f5fafd;
  border-radius: 12px;
  box-shadow: 0 1px 4px rgba(25,118,210,0.04);
  min-height: 42px;
  font-size: 1.1rem;
}

#output button {
  background: #e3f2fd;
  color: #1976d2;
  border: none;
  font-size: 1rem;
  border-radius: 20px;
  padding: 7px 20px;
  margin: 3px 8px 3px 0;
  box-shadow: 0 1px 4px rgba(25,118,210,0.10);
  transition: background 0.17s, color 0.17s;
}

#output button:hover, #output button:focus {
  background: #bbdefb;
  color: #0d47a1;
}

ul, ol {
  padding-left: 22px;
  margin-bottom: 18px;
}

li {
  margin-bottom: 7px;
}

a {
  color: #1976d2;
  text-decoration: none;
  font-weight: 500;
  transition: color 0.15s;
}

a:hover, a:focus {
  color: #0d47a1;
  text-decoration: underline;
}

p {
  line-height: 1.66;
  margin-bottom: 18px;
  color: #333;
}

section {
  margin-top: 30px;
  margin-bottom: 30px;
}

@media (max-width: 1000px) {
  #outer-container {
    padding: 18px 4vw 24px 4vw;
    max-width: 96vw;
  }
  textarea {
    width: 95vw;
    max-width: 98vw;
  }
}

@media (max-width: 600px) {
  h1 { font-size: 1.5rem; }
  h2 { font-size: 1.18rem; }
  #outer-container {
    padding: 12px 2vw 20px 2vw;
  }
  textarea {
    font-size: 1rem;
    padding: 8px;
  }
  button, #output button {
    font-size: 0.98rem;
    padding: 7px 13px;
    min-width: 80px;
  }
}
  
  #word-pred-container {
  background: #fff;
  margin: 32px auto 32px auto;
  max-width: 850px;
  box-shadow: 0 4px 20px rgba(0,0,0,0.09), 0 1.5px 5px rgba(0,0,0,0.04);
  border-radius: 16px;
  padding: 32px 40px 40px 40px;
  flex-direction: column;
  align-items: center;
}
@media (max-width: 1000px) {
  #word-pred-container {
    padding: 18px 4vw 24px 4vw;
    max-width: 96vw;
  }
}
@media (max-width: 600px) {
  #word-pred-container {
    padding: 12px 2vw 20px 2vw;
  }
}
    .helpbar {
  display: flex;
  align-items: center;
  background: #e3f2fd;        /* Sehr helles Material-Blue-100 */
  color: #1565c0;             /* Material-Blue-800 */
  padding: 12px 18px;
  border-radius: 10px;
  box-shadow: 0 1px 4px rgba(25, 118, 210, 0.11);
  margin: 18px 0 26px 0;
  font-size: 1.07rem;
  font-weight: 500;
}

.helpbar .material-icons {
  font-size: 1.7em;
  margin-right: 11px;
  color: #1976d2;           /* Material-Blue-600 für das Icon */
}

.error-message {
  background: #ffcdd2;
  color: #b71c1c;
  padding: 8px 18px;
  border-radius: 8px;
  margin: 14px 0;
  font-size: 1rem;
  font-weight: 500;
  box-shadow: 0 1px 6px rgba(211,47,47,0.09);
  display: none; /* Wird via JS angezeigt */
}

  </style>
</head>
<body>  
  <div id="word-pred-container">
  <h1>Wortvorhersage mit LSTM</h1>
  <h2>Vorhersage des nächsten Wortes</h2>
  <textarea id="input" rows="3" cols="60" placeholder="Gib hier deinen Satz ein..."></textarea>
  <div class="helpbar">
  <span class="material-icons" aria-hidden="true">info</span>
  <span id="helptext">Geben Sie einen Satz ein und klicken Sie auf "Vorhersage", um das nächste Wort zu erhalten. Über "Auto" wird der Satz automatisch ergänzt. Nutzen Sie "Stopp" und "Reset" zur Steuerung.</span>
  </div>
<button onclick="predictNext()" title="Nächstes Wort vorhersagen">Vorhersage</button>
<button onclick="continueText()" title="Fügt das wahrscheinlichste Wort hinzu">Weiter</button>
<button onclick="autoGenerate()" title="Satz automatisch ergänzen">Auto</button>
<button onclick="stopAuto()" title="Automatische Ergänzung stoppen">Stopp</button>
<button onclick="reset()" title="Eingabe und Vorhersage zurücksetzen">Reset</button>

  <div id="output" style="margin-top:20px;"></div>



</div>
<div id="outer-container">
  <h2>Dokumentation</h2>

  <h2>Überblick</h2>
  <p>
    This project implements an interactive web application that performs real-time 
    image classification using the MobileNet model through the ml5.js library. Users 
    can observe the classification of a predefined set of images or upload their own images through a modern user interface.
  </p>

  <section id="project-documentation">
 
<h2>Diskussion</h2>
<p>The pretrained model correctly classified familiar everyday objects, places, landscapes, and representatives of flora and fauna in most cases.
However, accurate classification generally required photos with good contrast, high resolution, and a clear depiction of the main object.
It was particularly striking that even a partial view, such as a fragment of a tandem bicycle, led to a highly accurate classification, although even the human eye struggles to detect the second set of pedals and handlebars.
On the other hand, the model's performance declined when images were more abstract, contained multiple objects, or when the objects showed a similar appearance but belonged to different classes.
For example, classifying the Laika dog breed proved difficult, as it is easily confused with other breeds or even wolves.
Several test images of this breed consistently resulted in misclassifications.
A notable failure also appeared in the recognition of the Eiffel Tower, where neither standard photographs nor mosaic representations were correctly classified.
This suggests that both landmarks and famous structures are not reliably recognized by the model.
Non-standard visual forms and artistic styles appear to pose a considerable challenge for accurate classification.
Overall, the experiment demonstrated both the strengths and the limitations of pretrained models when dealing with varying image complexities.</p>
<h2>1) Technical Documentation</h2>
 
  <h3>Verwendete Frameworks:</h3>
<ul>

<li><strong><a href="https://www.tensorflow.org/js" target="_blank">TensorFlowJS</a></strong>: zur Speicherung und Deployment des trainierten Netzes</li>
<li><strong><a href="https://www.tensorflow.org/guide/keras" target="_blank">TensorFlow bzw. Keras</a></strong>: zum Erstellen und Trainieren des Netzes</li>
<li><strong><a href="https://p5js.org/" target="_blank">JSON </a></strong>: zur Speicherung des Tokenizers (Wörterbuch)
</li>
<li><strong><a href="https://docs.github.com/en/pages" target="_blank">GitHub Pages</a></strong>: Eine Hosting-Plattform für statische Websites, 
  die für den öffentlichen Zugriff auf die Anwendung verwendet wird. Das Projekt wurde auf GitHub hochgeladen und kann dort direkt bereitgestellt werden.
</li>
</ul>
 
  <h3>Technische Dokumentation:</h3>
    <p><strong>Besonderheiten</strong><br>
Das Neuronale Netz und der Tokenizer wurden zuerst lokal in Python trainiert und in 
einem kompatiblem Format für TensorFlowJS gespeichert. Dies beschleunigte den Trainingsprozess und 
ermöglichte schnellere Experimente mit verschiedenen Parametrisierungen.</p>

   <p><strong>Umgebungen:</strong><br></p>
<ul>
<li>Training: Python 3.7.10 für Kompatibilität mit tensorflowjs</li>
<li>Deployment: JavaScript und HTML</li>
</ul>
    
 
  <h2>2) Subject-Specific Documentation</h2>
 
  <h3>Implementation of Logic and Key Elements:</h3>
<ul>
<ul>
<li>The application classifies a predefined set of static images using a pre-trained MobileNet model from ml5.js, dynamically displaying the results in a structured and adaptive table structure.</li>
<li>Image classification is triggered automatically in the setup() function after preloading the images using the preload() method. Each image and its corresponding diagram are added as a new row in the table, maintaining a clear and consistent structure.</li>
<li>Labels under each image serve to further explain the object being classified. The classification results are visualized using bar charts that show the three best predictions and their corresponding confidence percentages. By hovering over each of the bars, the specific numbers can be read.</li>
<li>A dedicated upload section allows users to classify their own images, providing visual and interactive consistency with the predefined examples.</li>
<li>The visual design follows Google’s Material Design guidelines: primary and accent colors, rounded shapes, consistent height (shadows), and responsive layouts are used to improve clarity and usability.</li>
<li>The interaction design is guided by the ISO 9241-110 principles of human-computer interaction, with a particular emphasis on:</li>
<ul>
<li>Task-fit: Simple, straightforward workflows for uploading and classifying images.</li>
<li>Self-descriptiveness: Clear labels and immediate feedback after actions.</li>
<li>Fault tolerance: Validation of supported file formats and sizes with user-friendly error messages.</li>
<li>Feedback and assistance: Visible hints about supported file types and immediate notifications of success after classification.</li>
</ul>
<li>Testing has shown that familiar, high-contrast objects are classified accurately, while abstract or complex scenes, such as mosaics or certain dog breeds, result in reduced accuracy or even misclassification.</li>
<li>Sources and references include official documentation from ml5.js, p5.js, and Chart.js, as well as design principles from Google's Material Design Guidelines.</li>
</ul>
 
</section>
</div>

  <script>
  let model;
  let wordIndex = {};
  let indexWord = {};
  const maxLen = 9; // sollte mit max_seq_len -1 aus Python übereinstimmen

  // Lade Modell und Tokenizer
  async function loadResources() {
    // Modell laden
    model = await tf.loadLayersModel('lm_tfjs/model.json');
    console.log("✅ Modell geladen");

    // Tokenizer laden
    const response = await fetch('tokenizer_word2index.json');
    const data_w2i = await response.json();
    const response2 = await fetch('tokenizer_index2word.json');
    const data_i2w = await response2.json();

    wordIndex = data_w2i //.config.word_index;
    indexWord = {};
    for (const key in data_i2w) {
      indexWord[parseInt(key)] = data_i2w[key];
    }

    console.log("✅ Tokenizer geladen mit", Object.keys(wordIndex).length, "Wörtern");

  }

  // Text -> Token-IDs (Array)
  function textToSequence(text) {
    // Kleinschreibung + Zeichen filtern + split
    const cleanText = text.toLowerCase().replace(/[^a-zäöüß0-9 ]/g, '').trim();
    const words = cleanText.split(/\s+/);
    console.log("Eingegebene Wörter:", words);

    const seq = words.map(w => {
      if (wordIndex[w]) {
        return wordIndex[w];
      } else {
        console.warn(`Wort nicht im Tokenizer gefunden: "${w}"`);
        return 0;
      }
    });
    const filteredSeq = seq.filter(x => x > 0);

    // if (filteredSeq.length === 0) {
    //   alert("Keine bekannten Wörter im Text!");
    // }

    function showError(msg) {
  let errBox = document.getElementById("errbox");
  if (!errBox) {
    errBox = document.createElement("div");
    errBox.id = "errbox";
    errBox.className = "error-message";
    document.getElementById("output").prepend(errBox);
  }
  errBox.textContent = msg;
  errBox.style.display = "block";
  setTimeout(() => errBox.style.display = "none", 4000);
}

// dann im Code:
if (filteredSeq.length === 0) {
  showError("Keine bekannten Wörter im Text!");
}


    console.log("Token-Sequenz:", filteredSeq);
    return filteredSeq;
  }

  // Padding von Sequenzen links mit 0, Länge maxLen
  function padSequence(seq) {
    //const padded = new Array(Math.abs(maxLen - seq.length)).fill(0).concat(seq).slice(-maxLen);
    const truncated = seq.slice(-maxLen); // schneidet von rechts, falls zu lang
    const padded = new Array(maxLen - truncated.length).fill(0).concat(truncated);
    return tf.tensor2d([padded]);
  }

  // Vorhersage machen und Top-5 Vorschläge anzeigen
  async function predictNext() {
    const inputText = document.getElementById("input").value.trim();
    if (!inputText) return alert("Bitte gib einen Text ein.");

    const seq = textToSequence(inputText);
    if (seq.length === 0) return; // keine bekannten Wörter

    console.log("Eingegebene Sequenz:", seq);
    const padded = padSequence(seq);
    console.log("Nach padding Sequenz:", seq);
    const prediction = model.predict(padded);
    const data = await prediction.data();

    // Top-5 Wörter mit Wahrscheinlichkeit
    const topWords = Array.from(data)
      .map((prob, idx) => ({ word: indexWord[idx], prob }))
      .filter(x => x.word)
      .sort((a, b) => b.prob - a.prob)
      .slice(0, 5);

    const outputDiv = document.getElementById("output");
    outputDiv.innerHTML = "<b>Wortvorschläge:</b><br>";
    topWords.forEach(w => {
      outputDiv.innerHTML += `<button onclick="addWord('${w.word}')">${w.word} (${(w.prob * 100).toFixed(2)}%)</button> `;
    });
  }

  // Wort ans Textfeld anhängen und neue Vorhersage starten
  function addWord(word) {
    const textarea = document.getElementById("input");
    textarea.value = (textarea.value + " " + word).trim();
    predictNext();
  }

  // Automatisch das wahrscheinlichste Wort anhängen
  let autoInterval;
  let autoCount = 0;
  const maxAutoWords = 10;

  async function autoGenerate() {
    // Falls schon läuft, nicht nochmal starten
    if (autoInterval) return;
    autoCount = 0;

    autoInterval = setInterval(async () => {
      if (autoCount >= maxAutoWords) {
        stopAuto();
        return;
      }
      await continueText(); // Funktion erweitert, siehe unten
      autoCount++;
    }, 1000); // alle 1 Sekunde ein Wort hinzufügen (anpassen nach Wunsch)
  }

  function stopAuto() {
    if (autoInterval) {
      clearInterval(autoInterval);
      autoInterval = null;
    }
  }

  function reset() {
    stopAuto();
    const textarea = document.getElementById("input");
    textarea.value = "";
    document.getElementById("output").innerHTML = "";
    // Falls du weitere Reset-Operationen hast, hier ergänzen
  }

  // continueText anpassen, damit sie async und Promise-konform ist
  async function continueText() {
    const inputText = document.getElementById("input").value.trim();
    if (!inputText) return;

    const sequence = textToSequence(inputText);
    const padded = padSequence(sequence);
    const data = await model.predict(padded).data();

    const topIndex = data.indexOf(Math.max(...data));
    const word = indexWord[topIndex];
    if (word) addWord(word);
  }

  loadResources();
</script>

</body>
</html>
