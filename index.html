<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8" />
  <title>Wortvorhersage mit LSTM</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.19.0/dist/tf.min.js"></script>
  <style>
    button {
      margin: 2px;
      padding: 6px 12px;
      font-size: 14px;
      cursor: pointer;
    }
    #output button {
      background-color: #f0f0f0;
      border: 1px solid #ccc;
      border-radius: 4px;
    }
    #output button:hover {
      background-color: #d0eaff;
    }
    h1, h2 {
      color: #1976d2;
    }
  </style>
</head>
<body>
  <h1>Wortvorhersage mit LSTM</h1>
  <h2>Vorhersage des nächsten Wortes</h2>
  <textarea id="input" rows="3" cols="60" placeholder="Gib hier deinen Satz ein..."></textarea><br><br>
  <button onclick="predictNext()">Vorhersage</button>
  <button onclick="continueText()">Weiter</button>
  <button onclick="autoGenerate()">Auto</button>
  <button onclick="stopAuto()">Stopp</button>
  <button onclick="reset()">Reset</button>
  <div id="output" style="margin-top:20px;"></div>

<div id="outer-container">
  <h1>Image Classification Web App using MobileNet and ml5.js</h1>

  <h2>Overview</h2>
  <p>
    This project implements an interactive web application that performs real-time 
    image classification using the MobileNet model through the ml5.js library. Users 
    can observe the classification of a predefined set of images or upload their own images through a modern user interface.
  </p>

  <section id="project-documentation">
 
<h2>Discussion</h2>
<p>The pretrained model correctly classified familiar everyday objects, places, landscapes, and representatives of flora and fauna in most cases.
However, accurate classification generally required photos with good contrast, high resolution, and a clear depiction of the main object.
It was particularly striking that even a partial view, such as a fragment of a tandem bicycle, led to a highly accurate classification, although even the human eye struggles to detect the second set of pedals and handlebars.
On the other hand, the model's performance declined when images were more abstract, contained multiple objects, or when the objects showed a similar appearance but belonged to different classes.
For example, classifying the Laika dog breed proved difficult, as it is easily confused with other breeds or even wolves.
Several test images of this breed consistently resulted in misclassifications.
A notable failure also appeared in the recognition of the Eiffel Tower, where neither standard photographs nor mosaic representations were correctly classified.
This suggests that both landmarks and famous structures are not reliably recognized by the model.
Non-standard visual forms and artistic styles appear to pose a considerable challenge for accurate classification.
Overall, the experiment demonstrated both the strengths and the limitations of pretrained models when dealing with varying image complexities.</p>
<h2>1) Technical Documentation</h2>
 
  <h3>Verwendete Frameworks:</h3>
<ul>

<li><strong><a href="https://www.tensorflow.org/js" target="_blank">TensorFlowJS</a></strong>: zur Speicherung und Deployment des trainierten Netzes</li>
<li><strong><a href="https://www.tensorflow.org/guide/keras" target="_blank">TensorFlow bzw. Keras</a></strong>: zum Erstellen und Trainieren des Netzes</li>
<li><strong><a href="https://p5js.org/" target="_blank">JSON </a></strong>: zur Speicherung des Tokenizers (Wörterbuch)
</li>
<li><strong><a href="https://docs.github.com/en/pages" target="_blank">GitHub Pages</a></strong>: Eine Hosting-Plattform für statische Websites, 
  die für den öffentlichen Zugriff auf die Anwendung verwendet wird. Das Projekt wurde auf GitHub hochgeladen und kann dort direkt bereitgestellt werden.
</li>
</ul>
 
  <h3>Technische Dokumentation:</h3>
    <p><strong>Besonderheiten</strong><br>
Das Neuronale Netz und der Tokenizer wurden zuerst lokal in Python trainiert und in 
einem kompatiblem Format für TensorFlowJS gespeichert. Dies beschleunigte den Trainingsprozess und 
ermöglichte schnellere Experimente mit verschiedenen Parametrisierungen.</p>

   <p><strong>Umgebungen:</strong><br></p>
<ul>
<li>Training: Python 3.7.10 für Kompatibilität mit tensorflowjs</li>
<li>Deployment: JavaScript und HTML</li>
</ul>
    
 
  <h2>2) Subject-Specific Documentation</h2>
 
  <h3>Implementation of Logic and Key Elements:</h3>
<ul>
<ul>
<li>The application classifies a predefined set of static images using a pre-trained MobileNet model from ml5.js, dynamically displaying the results in a structured and adaptive table structure.</li>
<li>Image classification is triggered automatically in the setup() function after preloading the images using the preload() method. Each image and its corresponding diagram are added as a new row in the table, maintaining a clear and consistent structure.</li>
<li>Labels under each image serve to further explain the object being classified. The classification results are visualized using bar charts that show the three best predictions and their corresponding confidence percentages. By hovering over each of the bars, the specific numbers can be read.</li>
<li>A dedicated upload section allows users to classify their own images, providing visual and interactive consistency with the predefined examples.</li>
<li>The visual design follows Google’s Material Design guidelines: primary and accent colors, rounded shapes, consistent height (shadows), and responsive layouts are used to improve clarity and usability.</li>
<li>The interaction design is guided by the ISO 9241-110 principles of human-computer interaction, with a particular emphasis on:</li>
<ul>
<li>Task-fit: Simple, straightforward workflows for uploading and classifying images.</li>
<li>Self-descriptiveness: Clear labels and immediate feedback after actions.</li>
<li>Fault tolerance: Validation of supported file formats and sizes with user-friendly error messages.</li>
<li>Feedback and assistance: Visible hints about supported file types and immediate notifications of success after classification.</li>
</ul>
<li>Testing has shown that familiar, high-contrast objects are classified accurately, while abstract or complex scenes, such as mosaics or certain dog breeds, result in reduced accuracy or even misclassification.</li>
<li>Sources and references include official documentation from ml5.js, p5.js, and Chart.js, as well as design principles from Google's Material Design Guidelines.</li>
</ul>
 
</section>
</div>

  <script>
  let model;
  let wordIndex = {};
  let indexWord = {};
  const maxLen = 9; // sollte mit max_seq_len -1 aus Python übereinstimmen

  // Lade Modell und Tokenizer
  async function loadResources() {
    // Modell laden
    model = await tf.loadLayersModel('lm_tfjs/model.json');
    console.log("✅ Modell geladen");

    // Tokenizer laden
    const response = await fetch('tokenizer_word2index.json');
    const data_w2i = await response.json();
    const response2 = await fetch('tokenizer_index2word.json');
    const data_i2w = await response2.json();

    wordIndex = data_w2i //.config.word_index;
    indexWord = {};
    for (const key in data_i2w) {
      indexWord[parseInt(key)] = data_i2w[key];
    }

    console.log("✅ Tokenizer geladen mit", Object.keys(wordIndex).length, "Wörtern");

  }

  // Text -> Token-IDs (Array)
  function textToSequence(text) {
    // Kleinschreibung + Zeichen filtern + split
    const cleanText = text.toLowerCase().replace(/[^a-zäöüß0-9 ]/g, '').trim();
    const words = cleanText.split(/\s+/);
    console.log("Eingegebene Wörter:", words);

    const seq = words.map(w => {
      if (wordIndex[w]) {
        return wordIndex[w];
      } else {
        console.warn(`Wort nicht im Tokenizer gefunden: "${w}"`);
        return 0;
      }
    });
    const filteredSeq = seq.filter(x => x > 0);

    if (filteredSeq.length === 0) {
      alert("Keine bekannten Wörter im Text!");
    }

    console.log("Token-Sequenz:", filteredSeq);
    return filteredSeq;
  }

  // Padding von Sequenzen links mit 0, Länge maxLen
  function padSequence(seq) {
    //const padded = new Array(Math.abs(maxLen - seq.length)).fill(0).concat(seq).slice(-maxLen);
    const truncated = seq.slice(-maxLen); // schneidet von rechts, falls zu lang
    const padded = new Array(maxLen - truncated.length).fill(0).concat(truncated);
    return tf.tensor2d([padded]);
  }

  // Vorhersage machen und Top-5 Vorschläge anzeigen
  async function predictNext() {
    const inputText = document.getElementById("input").value.trim();
    if (!inputText) return alert("Bitte gib einen Text ein.");

    const seq = textToSequence(inputText);
    if (seq.length === 0) return; // keine bekannten Wörter

    console.log("Eingegebene Sequenz:", seq);
    const padded = padSequence(seq);
    console.log("Nach padding Sequenz:", seq);
    const prediction = model.predict(padded);
    const data = await prediction.data();

    // Top-5 Wörter mit Wahrscheinlichkeit
    const topWords = Array.from(data)
      .map((prob, idx) => ({ word: indexWord[idx], prob }))
      .filter(x => x.word)
      .sort((a, b) => b.prob - a.prob)
      .slice(0, 5);

    const outputDiv = document.getElementById("output");
    outputDiv.innerHTML = "<b>Wortvorschläge:</b><br>";
    topWords.forEach(w => {
      outputDiv.innerHTML += `<button onclick="addWord('${w.word}')">${w.word} (${(w.prob * 100).toFixed(2)}%)</button> `;
    });
  }

  // Wort ans Textfeld anhängen und neue Vorhersage starten
  function addWord(word) {
    const textarea = document.getElementById("input");
    textarea.value = (textarea.value + " " + word).trim();
    predictNext();
  }

  // Automatisch das wahrscheinlichste Wort anhängen
  let autoInterval;
  let autoCount = 0;
  const maxAutoWords = 10;

  async function autoGenerate() {
    // Falls schon läuft, nicht nochmal starten
    if (autoInterval) return;
    autoCount = 0;

    autoInterval = setInterval(async () => {
      if (autoCount >= maxAutoWords) {
        stopAuto();
        return;
      }
      await continueText(); // Funktion erweitert, siehe unten
      autoCount++;
    }, 1000); // alle 1 Sekunde ein Wort hinzufügen (anpassen nach Wunsch)
  }

  function stopAuto() {
    if (autoInterval) {
      clearInterval(autoInterval);
      autoInterval = null;
    }
  }

  function reset() {
    stopAuto();
    const textarea = document.getElementById("input");
    textarea.value = "";
    document.getElementById("output").innerHTML = "";
    // Falls du weitere Reset-Operationen hast, hier ergänzen
  }

  // continueText anpassen, damit sie async und Promise-konform ist
  async function continueText() {
    const inputText = document.getElementById("input").value.trim();
    if (!inputText) return;

    const sequence = textToSequence(inputText);
    const padded = padSequence(sequence);
    const data = await model.predict(padded).data();

    const topIndex = data.indexOf(Math.max(...data));
    const word = indexWord[topIndex];
    if (word) addWord(word);
  }

  loadResources();
</script>

</body>
</html>
